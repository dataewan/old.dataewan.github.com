{"version":3,"sources":["webpack:///./src/pages/learning/statistics/bayesian-inference/index.js","webpack:///./src/pages/learning/statistics/bayesian-inference/partsOfEquation.js","webpack:///./src/pages/learning/statistics/bayesian-inference/bayes_rule.png"],"names":["StatsIndexPage","name","caption","src","bayes_rule","to","equation","PartsOfEquation","style","border","Constants","lightyellow","padding","lightblue","lightgreen","lightred","module","exports"],"mappings":"8FAAA,kGAwEeA,UAnDQ,kBACrB,kBAAC,IAAD,KACE,kBAAC,IAAD,CAASC,KAAK,sBACZ,kBAAC,IAAD,6NAKA,kBAAC,IAAD,CAAQC,QAAQ,kDACd,yBAAKC,IAAKC,OAEZ,kBAAC,IAAD,8CAEE,kBAAC,UAAD,OAEF,kBAAC,IAAD,+CACyC,0CADzC,MAC+D,IAC7D,0CAFF,kLAMA,kBAAC,IAAD,8TAOA,kBAAC,IAAD,CAAYH,KAAK,iCACf,kBAAC,IAAD,+JAGwB,IACtB,kBAAC,IAAD,CAAMI,GAAG,sDAAT,8BAEQ,IANV,mDASA,kBAAC,IAAD,KACE,kBAAC,IAAD,CAAUC,SAAS,wEACnB,kBAAC,IAAD,CAAUA,SAAS,+DAErB,kBAAC,IAAD,6DACuD,kBAAC,IAAD,CAAMD,GAAG,kDAAT,qCADvD,2I,kCC/DR,iEA6CeE,UAxCS,kBACtB,6BACE,yBAAKC,MAAO,CAAEC,OAAM,aAAgBC,IAAUC,YAAeC,QAAU,KACrE,kBAAC,IAAD,CAAMP,GAAG,sDACP,yDACA,mGAKJ,yBAAKG,MAAO,CAAEC,OAAM,aAAgBC,IAAUG,UAAaD,QAAU,KACnE,kBAAC,IAAD,CAAMP,GAAG,iDACP,6CACA,iIAMJ,yBAAKG,MAAO,CAAEC,OAAM,aAAgBC,IAAUI,WAAcF,QAAU,KACpE,kBAAC,IAAD,CAAMP,GAAG,oDACP,mDACA,2FACgE,IAC9D,mDAFF,OAMJ,yBAAKG,MAAO,CAAEC,OAAM,aAAgBC,IAAUK,SAAYH,QAAU,KAClE,kBAAC,IAAD,CAAMP,GAAG,qDACP,wDACA,gJ,qBCpCRW,EAAOC,QAAU,IAA0B","file":"component---src-pages-learning-statistics-bayesian-inference-index-js-721f96a98f4c15ed913c.js","sourcesContent":["import React from \"react\";\nimport Link from \"gatsby-link\";\n\nimport {\n  Paragraph,\n  BlockQuote,\n  Section,\n  Subsection,\n  Code,\n  Figure,\n  Linknode,\n  Linktree,\n  Constants,\n  Layout,\n  Equation\n} from \"../../../../components\";\n\nimport PartsOfEquation from \"./partsOfEquation\";\n\nimport bayes_rule from \"./bayes_rule.png\";\n\nconst StatsIndexPage = () => (\n  <Layout>\n    <Section name=\"Bayesian inference\">\n      <Paragraph>\n        Bayesian inference is a way of drawing statistical inferences from data.\n        You make a model with parameters θ. You then use Bayes rule to get the\n        probability distribution for those parameters after we observe data.\n      </Paragraph>\n      <Figure caption=\"Bayes rule for the probability of θ given data\">\n        <img src={bayes_rule} />\n      </Figure>\n      <Paragraph>\n        There are four parts to this equation.\n        <PartsOfEquation />\n      </Paragraph>\n      <Paragraph>\n        Bayes rule gives you a way to get from <i>p(data | θ)</i> to{\" \"}\n        <i>p(θ | data)</i>, flipping round the equation to give you the\n        posterior. An alternative way of thinking about it is that it gives you\n        a way to update your beliefs after you observe new data.\n      </Paragraph>\n      <Paragraph>\n        We go to a lot of hard work to calculate the posterior distribution,\n        which is what the data tells you about the parameters of your model.\n        From the posterior you can make summaries of your analysis to state the\n        likely values of the parameters of the model, and you can also make\n        predictions from the posterior.\n      </Paragraph>\n      <Subsection name=\"Sampling to get the posterior\">\n        <Paragraph>\n          The posterior is really hard to calculate exactly, because the\n          evidence term is usually a horrible integral. We take advantage of\n          something we found in{\" \"}\n          <Link to=\"./learning/statistics/bayesian-inference/evidence/\">\n            the section about evidence\n          </Link>{\" \"}\n          to rewrite Bayes rule as a similarity relation.\n        </Paragraph>\n        <Paragraph>\n          <Equation equation=\"$p(\\theta | data) = \\frac{p(data | \\theta) p(\\theta)}{p(data)}$\" />\n          <Equation equation=\"$p(\\theta | data) \\propto p(data | \\theta) p(\\theta)$\" />\n        </Paragraph>\n        <Paragraph>\n          This trick lets us use a family of techniques called <Link to=\"./learning/statistics/bayesian-inference/mcmc/\">Markov Chain Monte Carlo sampling</Link>.\n          These techniques let us get a very good approximation of the posterior distribution, and allows us to solve real world problems.\n        </Paragraph>\n      </Subsection>\n    </Section>\n  </Layout>\n);\n\nexport default StatsIndexPage;\n","import React from \"react\";\nimport Link from \"gatsby-link\";\n\nimport Constants from \"../../../../components/constants\";\n\nconst PartsOfEquation = () => (\n  <div>\n    <div style={{ border : `solid 5px ${Constants.lightyellow}`, padding : 10 }}>\n      <Link to=\"/learning/statistics/bayesian-inference/likelihood\">\n        <h3>Likelihood — p(data | θ) </h3>\n        <p>\n          Given our model, how likely is it that we would observe this data?\n        </p>\n      </Link>\n    </div>\n    <div style={{ border : `solid 5px ${Constants.lightblue}`, padding : 10 }}>\n      <Link to=\"/learning/statistics/bayesian-inference/prior\">\n        <h3>Prior — p(θ) </h3>\n        <p>\n          Before doing the inference, describe what you think the parameters are\n          by specifying the priors.\n        </p>\n      </Link>\n    </div>\n    <div style={{ border : `solid 5px ${Constants.lightgreen}`, padding : 10 }}>\n      <Link to=\"/learning/statistics/bayesian-inference/evidence\">\n        <h3>Evidence — p(data) </h3>\n        <p>\n          The denominator of Bayes rule. I've also seen this called the{\" \"}\n          <i>marginal probability</i>.\n        </p>\n      </Link>\n    </div>\n    <div style={{ border : `solid 5px ${Constants.lightred}`, padding : 10 }}>\n      <Link to=\"/learning/statistics/bayesian-inference/posterior\">\n        <h3>Posterior — p(θ | data) </h3>\n        <p>\n          This is the thing that we're trying to calculate. What are the values\n          of θ that we should use for our model?\n        </p>\n      </Link>\n    </div>\n  </div>\n);\n\nexport default PartsOfEquation;\n","module.exports = __webpack_public_path__ + \"static/bayes_rule-94c052427fc2797095ddd09ac553e974.png\";"],"sourceRoot":""}