{"version":3,"sources":["webpack:///./src/pages/learning/statistics/bayesian-inference/evidence/index.js"],"names":["EvidenceTerm","name","equation","note","href"],"mappings":"2FAAA,wDAkEeA,UAlDM,kBACnB,kBAAC,IAAD,KACE,kBAAC,IAAD,CAASC,KAAK,YACZ,kBAAC,IAAD,iPAMA,kBAAC,IAAD,iFAGA,kBAAC,IAAD,KACE,kBAAC,IAAD,CAAUC,SAAS,2DAErB,kBAAC,IAAD,+QAMA,kBAAC,IAAD,CAAYD,KAAK,4CACf,kBAAC,IAAD,CACEE,KACE,uBAAGC,KAAK,iDAAR,oBAFJ,yNAYA,kBAAC,IAAD,6UAOA,kBAAC,IAAD,KACE,kBAAC,IAAD,CAAUF,SAAS,wEACnB,kBAAC,IAAD,CAAUA,SAAS","file":"component---src-pages-learning-statistics-bayesian-inference-evidence-index-js-6547360c199a3673cabf.js","sourcesContent":["import React from \"react\";\nimport Link from \"gatsby-link\";\n\nimport {\n  Paragraph,\n  BlockQuote,\n  Section,\n  Subsection,\n  Code,\n  Figure,\n  Linknode,\n  Linktree,\n  Layout,\n  Equation\n} from \"../../../../../components\";\n\nconst EvidenceTerm = () => (\n  <Layout>\n    <Section name=\"Evidence\">\n      <Paragraph>\n        The evidence is the tricky bit and what makes bayesian inference more\n        difficult. What this term describes is the evidence that the data was\n        generated by the model. Note that this term is independent of the\n        parameters Î¸ of the model.\n      </Paragraph>\n      <Paragraph>\n        We can calculate this by integrating over all possible parameter values.\n      </Paragraph>\n      <Paragraph>\n        <Equation equation=\"$p(data) = \\int_{\\theta} p(data, \\theta) d\\theta$\" />\n      </Paragraph>\n      <Paragraph>\n        This integral is what makes Bayes rule so tricky. For non-trivial models\n        there is no closed form way to calculate this. The more parameters your\n        model has, the more parameters that you need to integrate over. For\n        real-world models it seems like we're in trouble.\n      </Paragraph>\n      <Subsection name=\"Using sampling to avoid this calculation\">\n        <Paragraph\n          note={\n            <a href=\"https://en.wikipedia.org/wiki/Conjugate_prior\">\n              Conjugate prior\n            </a>\n          }\n        >\n          To get an exact answer to this you need to use a conjugate prior, a\n          set of distributions that are related to the likelihood in a\n          mathematically nice way. This is very limiting, and not suitable for\n          the real world.\n        </Paragraph>\n        <Paragraph>\n          What we do these days is use computers to avoid this problem by\n          sampling. This trick depends on noticing that the evidence term\n          doesn't depend on the parameters of the model.\n          That means that the shape of the posterior only depends on the numerator of Bayes rule,\n          and we can simplify what we are going to calculate like this:\n        </Paragraph>\n        <Paragraph>\n          <Equation equation=\"$p(\\theta | data) = \\frac{p(data | \\theta) p(\\theta)}{p(data)}$\"/>\n          <Equation equation=\"$p(\\theta | data) \\propto p(data | \\theta) p(\\theta)$\"/>\n        </Paragraph>\n      </Subsection>\n    </Section>\n  </Layout>\n);\n\nexport default EvidenceTerm;\n"],"sourceRoot":""}