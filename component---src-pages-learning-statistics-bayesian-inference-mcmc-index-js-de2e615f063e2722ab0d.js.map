{"version":3,"sources":["webpack:///./src/pages/learning/statistics/bayesian-inference/mcmc/index.js"],"names":["MCMCPage","name","equation","note","href","language","code"],"mappings":"4FAAA,6EA0IeA,UAvHE,kBACf,kBAAC,IAAD,KACE,kBAAC,IAAD,CAASC,KAAK,4CACZ,kBAAC,IAAD,4EAGA,kBAAC,IAAD,KACE,kBAAC,IAAD,CAAUC,SAAS,+DAErB,kBAAC,IAAD,kGAEqB,0CAFrB,qBAEyD,mCAFzD,iIAMA,kBAAC,IAAD,wHAIA,kBAAC,IAAD,CACEC,KACE,6BACE,uBAAGC,KAAK,4DAAR,6BAGA,6BACA,uBAAGA,KAAK,4CAAR,4BAPN,8YAoBA,kBAAC,IAAD,CAAYH,KAAK,mCACf,kBAAC,IAAD,mHAEsC,kBAAC,IAAD,iBAFtC,MAKF,kBAAC,IAAD,CAAYA,KAAK,0BACf,kBAAC,IAAD,4JAGkB,kBAAC,IAAD,iBAHlB,yDAIwB,wCAJxB,KAMA,kBAAC,IAAD,KACE,kBAAC,IAAD,CAAUC,SAAS,sDAErB,kBAAC,IAAD,KACE,wCADF,gKAMF,kBAAC,IAAD,CAAYD,KAAK,uFACf,kBAAC,IAAD,+DAGA,kBAAC,IAAD,KACE,kBAAC,IAAD,CAAUC,SAAS,oCAErB,kBAAC,IAAD,yOAKA,kBAAC,IAAD,CACEG,SAAS,SACTC,KAAI,uOAON,kBAAC,IAAD,0KAIA,kBAAC,IAAD,CACED,SAAS,SACTC,KAAI,sJAMR,kBAAC,IAAD,CAAYL,KAAK,sCACf,kBAAC,IAAD,gHAEY,gCAFZ,KAIA,kBAAC,IAAD,KACE,kBAAC,IAAD,CAAUC,SAAS,gFAErB,kBAAC,IAAD,WACK,gCADL,yIAGA,kBAAC,IAAD,mKAGQ,gCAHR,kEAG+E,gCAH/E,KAKA,kBAAC,IAAD","file":"component---src-pages-learning-statistics-bayesian-inference-mcmc-index-js-de2e615f063e2722ab0d.js","sourcesContent":["import React from \"react\";\nimport Link from \"gatsby-link\";\n\nimport Latex from \"react-latex\";\n\nimport {\n  Paragraph,\n  BlockQuote,\n  Section,\n  Subsection,\n  Code,\n  Figure,\n  Linknode,\n  Linktree,\n  Constants,\n  Layout,\n  Equation\n} from \"../../../../../components\";\n\nconst MCMCPage = () => (\n  <Layout>\n    <Section name=\"Markov Chain Monte Carlo (MCMC) sampling\">\n      <Paragraph>\n        Markov Chain Monte Carlo (MCMC) uses this description of Bayes rule\n      </Paragraph>\n      <Paragraph>\n        <Equation equation=\"$p(\\theta | data) \\propto p(data | \\theta) p(\\theta)$\" />\n      </Paragraph>\n      <Paragraph>\n        Where we say that the shape of the posterior distribution only depends\n        on the likelihood (<i>p(data | θ)</i>), and the prior (<i>p(θ)</i>).\n        We're able to generate samples from a distribution that has exactly the\n        same shape as the posterior, but isn't normalised.\n      </Paragraph>\n      <Paragraph>\n        MCMC is a set of techniques that draw samples from the posterior\n        probability distribution, using this property.\n      </Paragraph>\n      <Paragraph\n        note={\n          <div>\n            <a href=\"https://twiecki.github.io/blog/2015/11/10/mcmc-sampling/\">\n              MCMC sampling for dummies\n            </a>\n            <br />\n            <a href=\"https://github.com/dataewan/handcut-mcmc\">\n              Handcut MCMC in python\n            </a>\n          </div>\n        }\n      >\n        I'll demonstrate one type of MCMC called Metropolis sampling. There's a\n        really good blog post called MCMC sampling for dummies, which\n        demonstrates this technique using Python. I wrote out this Python code,\n        and this gave me a good intuition of Metropolis sampling. It describes\n        fitting a simple model to data: with 20 data points, what is the mean of\n        the normal distribution that fits this data?\n      </Paragraph>\n      <Subsection name=\"1. Start with a parameter value\">\n        <Paragraph>\n          We start with a value for the model parameter. This value that we pick\n          is arbitrary. We'll call this value <Latex>$\\mu_c$</Latex>.\n        </Paragraph>\n      </Subsection>\n      <Subsection name=\"2. Propose a new value\">\n        <Paragraph>\n          The next thing that we do is propose a new value for the model\n          parameters. We do this by taking a sample from a normal distribution\n          with mean value <Latex>$\\mu_c$</Latex>, and with a standard deviation\n          of a parameter called <i>step size</i>.\n        </Paragraph>\n        <Paragraph>\n          <Equation equation=\"$\\mu_p \\sim \\mathcal{N}(\\mu_c, step\\ size)$\" />\n        </Paragraph>\n        <Paragraph>\n          <i>step size</i> is a parameter we can set. If we set this bigger then\n          we'll take larger jumps, if we set it smaller then we make smaller\n          jumps from one point to the next.\n        </Paragraph>\n      </Subsection>\n      <Subsection name=\"3. Calculate the likelihood and prior values for the current and proposed parameter\">\n        <Paragraph>\n          We want to calculate the nominator part of Bayes rule:\n        </Paragraph>\n        <Paragraph>\n          <Equation equation=\"$p(data | \\theta) p(\\theta)$\" />\n        </Paragraph>\n        <Paragraph>\n          This is the likelihood multiplied by the prior. The likelihood is how\n          likely it is for the data to be generated from a normal distribution\n          with that mean. We get the probability for each datapoint and multiply them together.\n        </Paragraph>\n        <Code\n          language=\"python\"\n          code={`\n# We're assuming that the standard deviation is fixed at 1, \n# and only the mean changes.\nlikelihood_current = stats.norm(mu_current, 1).pdf(data).prod()\nlikelihood_proposal = stats.norm(mu_proposal, 1).pdf(data).prod()\n`}\n        />\n        <Paragraph>\n          The prior is how credible we thought that value for\n          mean was before we looked at the data. We described our prior as a normal distribution that we parameterised.\n        </Paragraph>\n        <Code\n          language=\"python\"\n          code={`\nprior_current = stats.norm(mu_prior_mu, mu_prior_sd).pdf(mu_current)\nprior_proposal = stats.norm(mu_prior_mu, mu_prior_sd).pdf(mu_proposal)\n`}\n        />\n      </Subsection>\n      <Subsection name=\"4. Should we accept the new point?\">\n        <Paragraph>\n          We calculate the ratio between these two numerator terms for the proposed and current points. \n          Call this <i>r</i>.\n        </Paragraph>\n        <Paragraph>\n          <Equation equation=\"$r = \\frac{p(data | \\theta_p)p(theta_p)}{p(data | \\theta_c)p(theta_c)}$\" />\n        </Paragraph>\n        <Paragraph>\n          If <i>r</i> is greater than 1, that means that the new parameter is a better description than the previous one, and we always accept this point.\n        </Paragraph>\n        <Paragraph>\n          But we don't want to only accept better points.\n          If we do that we get stuck at a maximum point of the distribution and don't explore the whole space.\n          So if <i>r</i> is less than 1 we accept that point with probability equal to <i>r</i>.\n        </Paragraph>\n        <Paragraph>\n          We now loop round to step 1 again,\n          but with our new value for μ, or our old one if we rejected the new point.\n        </Paragraph>\n      </Subsection>\n    </Section>\n  </Layout>\n);\n\nexport default MCMCPage;\n"],"sourceRoot":""}