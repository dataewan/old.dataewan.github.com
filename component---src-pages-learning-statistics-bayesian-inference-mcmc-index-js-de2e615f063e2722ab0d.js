(window.webpackJsonp=window.webpackJsonp||[]).push([[10],{Qvae:function(e,t,a){"use strict";a.r(t);var n=a("q1tI"),r=a.n(n),l=(a("+ZDr"),a("SUaA")),o=a.n(l),i=a("Kvkj");t.default=function(){return r.a.createElement(i.e,null,r.a.createElement(i.j,{name:"Markov Chain Monte Carlo (MCMC) sampling"},r.a.createElement(i.h,null,"Markov Chain Monte Carlo (MCMC) uses this description of Bayes rule"),r.a.createElement(i.h,null,r.a.createElement(i.c,{equation:"$p(\\theta | data) \\propto p(data | \\theta) p(\\theta)$"})),r.a.createElement(i.h,null,"Where we say that the shape of the posterior distribution only depends on the likelihood (",r.a.createElement("i",null,"p(data | θ)"),"), and the prior (",r.a.createElement("i",null,"p(θ)"),"). We're able to generate samples from a distribution that has exactly the same shape as the posterior, but isn't normalised."),r.a.createElement(i.h,null,"MCMC is a set of techniques that draw samples from the posterior probability distribution, using this property."),r.a.createElement(i.h,{note:r.a.createElement("div",null,r.a.createElement("a",{href:"https://twiecki.github.io/blog/2015/11/10/mcmc-sampling/"},"MCMC sampling for dummies"),r.a.createElement("br",null),r.a.createElement("a",{href:"https://github.com/dataewan/handcut-mcmc"},"Handcut MCMC in python"))},"I'll demonstrate one type of MCMC called Metropolis sampling. There's a really good blog post called MCMC sampling for dummies, which demonstrates this technique using Python. I wrote out this Python code, and this gave me a good intuition of Metropolis sampling. It describes fitting a simple model to data: with 20 data points, what is the mean of the normal distribution that fits this data?"),r.a.createElement(i.k,{name:"1. Start with a parameter value"},r.a.createElement(i.h,null,"We start with a value for the model parameter. This value that we pick is arbitrary. We'll call this value ",r.a.createElement(o.a,null,"$\\mu_c$"),".")),r.a.createElement(i.k,{name:"2. Propose a new value"},r.a.createElement(i.h,null,"The next thing that we do is propose a new value for the model parameters. We do this by taking a sample from a normal distribution with mean value ",r.a.createElement(o.a,null,"$\\mu_c$"),", and with a standard deviation of a parameter called ",r.a.createElement("i",null,"step size"),"."),r.a.createElement(i.h,null,r.a.createElement(i.c,{equation:"$\\mu_p \\sim \\mathcal{N}(\\mu_c, step\\ size)$"})),r.a.createElement(i.h,null,r.a.createElement("i",null,"step size")," is a parameter we can set. If we set this bigger then we'll take larger jumps, if we set it smaller then we make smaller jumps from one point to the next.")),r.a.createElement(i.k,{name:"3. Calculate the likelihood and prior values for the current and proposed parameter"},r.a.createElement(i.h,null,"We want to calculate the nominator part of Bayes rule:"),r.a.createElement(i.h,null,r.a.createElement(i.c,{equation:"$p(data | \\theta) p(\\theta)$"})),r.a.createElement(i.h,null,"This is the likelihood multiplied by the prior. The likelihood is how likely it is for the data to be generated from a normal distribution with that mean. We get the probability for each datapoint and multiply them together."),r.a.createElement(i.b,{language:"python",code:"\n# We're assuming that the standard deviation is fixed at 1, \n# and only the mean changes.\nlikelihood_current = stats.norm(mu_current, 1).pdf(data).prod()\nlikelihood_proposal = stats.norm(mu_proposal, 1).pdf(data).prod()\n"}),r.a.createElement(i.h,null,"The prior is how credible we thought that value for mean was before we looked at the data. We described our prior as a normal distribution that we parameterised."),r.a.createElement(i.b,{language:"python",code:"\nprior_current = stats.norm(mu_prior_mu, mu_prior_sd).pdf(mu_current)\nprior_proposal = stats.norm(mu_prior_mu, mu_prior_sd).pdf(mu_proposal)\n"})),r.a.createElement(i.k,{name:"4. Should we accept the new point?"},r.a.createElement(i.h,null,"We calculate the ratio between these two numerator terms for the proposed and current points. Call this ",r.a.createElement("i",null,"r"),"."),r.a.createElement(i.h,null,r.a.createElement(i.c,{equation:"$r = \\frac{p(data | \\theta_p)p(theta_p)}{p(data | \\theta_c)p(theta_c)}$"})),r.a.createElement(i.h,null,"If ",r.a.createElement("i",null,"r")," is greater than 1, that means that the new parameter is a better description than the previous one, and we always accept this point."),r.a.createElement(i.h,null,"But we don't want to only accept better points. If we do that we get stuck at a maximum point of the distribution and don't explore the whole space. So if ",r.a.createElement("i",null,"r")," is less than 1 we accept that point with probability equal to ",r.a.createElement("i",null,"r"),"."),r.a.createElement(i.h,null,"We now loop round to step 1 again, but with our new value for μ, or our old one if we rejected the new point."))))}}}]);
//# sourceMappingURL=component---src-pages-learning-statistics-bayesian-inference-mcmc-index-js-de2e615f063e2722ab0d.js.map